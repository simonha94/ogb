{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35243fdc",
   "metadata": {},
   "source": [
    "# Load Data and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "51afb6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7b76c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = np.load('cora_ml.npz', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6d4b61e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idx_to_attr', 'attr_indices', 'attr_shape', 'idx_to_node', 'adj_shape', 'adj_indptr', 'adj_data', 'labels', 'attr_data', 'adj_indices', 'attr_indptr', 'idx_to_class', 'attr_text']\n"
     ]
    }
   ],
   "source": [
    "print(cora.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "5a167b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(g['idx_to_attr']) # mapping id to string (2879)\n",
    "#print((g['attr_indices'])) # all indices\n",
    "#print(g['attr_shape']) # (2995, 2879)\n",
    "#print(g['idx_to_node']) # (2995)\n",
    "#print(g['adj_shape']) # (2995, 2995) adjacency shape\n",
    "#print(g['adj_indptr']) (8416)\n",
    "#print(g['adj_data']) 8416\n",
    "#print(g['labels']) 2995\n",
    "#print(g['attr_data'].shape) # 151171\n",
    "#print(g['adj_indices']) 8416\n",
    "#print(g['attr_indptr']) 151171\n",
    "#print(g['idx_to_class']) class strings\n",
    "\n",
    "print(len(cora['attr_text'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f5ca3",
   "metadata": {},
   "source": [
    "# Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "15fc1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_from_document(doc_str, isdirected, isweighted, size_window):\n",
    "    #doc_str is a string (i.e the document)\n",
    "    #doc_str should have more words than size_window\n",
    "    import networkx as nx\n",
    "    doc_array = doc_str.split()\n",
    "    N = len(doc_array)\n",
    "    \n",
    "    if isdirected:\n",
    "        G = nx.DiGraph()\n",
    "    else:\n",
    "        G=nx.Graph()\n",
    "        \n",
    "    for j in range(N):\n",
    "        for i in range(max(j-size_window+1,0),j):\n",
    "            if G.has_edge(doc_array[i], doc_array[j]):\n",
    "                if isweighted:\n",
    "                    # we added this one before, just increase the weight by one\n",
    "                    G[doc_array[i]][doc_array[j]]['weight'] += 1\n",
    "            else:\n",
    "                # new edge. add with weight=1\n",
    "                G.add_edge(doc_array[i], doc_array[j], weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "def get_gow(corpus, isdirected, isweighted, size_window):\n",
    "    dict_graph_of_words = dict()\n",
    "    \n",
    "    for i in range(corpus.shape[0]):\n",
    "            dict_graph_of_words[i] = get_graph_from_document(corpus[i],isdirected,isweighted, size_window)\n",
    "        \n",
    "    return dict_graph_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a833dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_graph_of_words = get_gow(cora['attr_text'],False,True,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c1402005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dict_graph_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d0a6a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform to torch_geometric and attach labels\n",
    "\n",
    "from torch_geometric.utils import from_networkx\n",
    "import torch\n",
    "\n",
    "torch_geometric_graphlist = []\n",
    "for key, value in dict_graph_of_words.items():\n",
    "    torch_geometric_graphlist.append(from_networkx(value))\n",
    "\n",
    "\n",
    "for i, graph in enumerate(torch_geometric_graphlist):\n",
    "  graph.y = torch.tensor(cora['labels'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed2c65",
   "metadata": {},
   "source": [
    "# Word2Vec for Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9b796840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "# Show all available models in gensim-data\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d2db579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a05e1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(X):\n",
    "  full_array = []\n",
    "  for i, text in enumerate(X):\n",
    "    text_array = []\n",
    "    for word in get_unique_words(text):\n",
    "      try:\n",
    "        text_array.append(wv[word])\n",
    "      except KeyError:\n",
    "        text_array.append(np.zeros(50))\n",
    "    full_array.append(text_array)\n",
    "  return full_array\n",
    "\n",
    "def get_unique_words(text):\n",
    "  uniques = []\n",
    "  for word in text.split():\n",
    "    if word not in uniques:\n",
    "      uniques.append(word)\n",
    "  return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "94ef5845",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_list = get_node_features(cora['attr_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe0ab5",
   "metadata": {},
   "source": [
    "# Steps to convert dataset to OGB object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "7dfc9118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ogb in /home/simon/.local/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (1.2.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (1.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from ogb) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (0.24.2)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (0.2.1)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/lib/python3/dist-packages (from ogb) (1.25.8)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/simon/.local/lib/python3.8/site-packages (from ogb) (4.61.1)\n",
      "Requirement already satisfied: littleutils in /home/simon/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from outdated>=0.2.0->ogb) (2.22.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.24.0->ogb) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.24.0->ogb) (2.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/simon/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/simon/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/simon/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/simon/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.10.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Found an existing submission directory at submission_ogbg_CoraAbstracts/. \n",
      "Will you remove it? (y/N)\n",
      "y\n",
      "Removed existing submission directory\n"
     ]
    }
   ],
   "source": [
    "#1. Constructor\n",
    "!pip install ogb\n",
    "from ogb.io import DatasetSaver\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "# constructor\n",
    "dataset_name = 'ogbg-CoraAbstracts'\n",
    "saver = DatasetSaver(dataset_name = dataset_name, is_hetero = False, version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "46bfafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['node_feat', 'num_nodes', 'edge_index', 'edge_feat'])\n",
      "Saving edge_index\n",
      "Saving all the files!\n",
      "Validating...\n",
      "Reading saved files\n",
      "Loading necessary files...\n",
      "This might take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2995/2995 [00:00<00:00, 460144.34it/s]\n",
      " 29%|██▉       | 870/2995 [00:00<00:00, 8694.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graphs...\n",
      "Checking read graphs and given graphs are the same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2995/2995 [00:00<00:00, 7366.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. Saving graph list\n",
    "# generate random graphs with node and edge features\n",
    "graph_list = []\n",
    "num_data = 100\n",
    "for i, g in enumerate(torch_geometric_graphlist):\n",
    "\n",
    "    graph = dict()\n",
    "    \n",
    "    #Word2Vec node features\n",
    "    graph['node_feat'] = np.array(node_features_list[i])\n",
    "    graph['num_nodes'] = len(node_features_list[i])\n",
    "    \n",
    "    graph['edge_index'] = np.array(g.edge_index) #.transpose() \n",
    "    num_edges = graph['edge_index'].shape[1]\n",
    "    graph['edge_feat'] = np.expand_dims(np.array(g.weight),axis=1).astype(np.int64)\n",
    "\n",
    "    \n",
    "    graph_list.append(graph)\n",
    "# saving a list of graphs\n",
    "saver.save_graph_list(graph_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "57298f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to transform labels\n",
    "def scalar_to_vector(scalar, num_classes):\n",
    "  t = np.zeros(num_classes)\n",
    "  t[scalar - 1] = 1\n",
    "  return t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "55400ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 433], weight=[433], y=3)\n",
      "(2995, 7)\n"
     ]
    }
   ],
   "source": [
    "# 3. Saving target labels\n",
    "num_classes = 7\n",
    "labels = []\n",
    "print(g)\n",
    "for i, l in enumerate(cora['labels']):\n",
    "  labels.append(scalar_to_vector(l, 7))\n",
    "\n",
    "#print(labels)\n",
    "labels = np.array([np.array(t) for t in labels]) #.transpose()\n",
    "print(labels.shape)\n",
    "saver.save_target_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c9355cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Saving dataset split\n",
    "split_idx = dict()\n",
    "num_data = len(bigram_count_adjacency_list)\n",
    "perm = np.random.permutation(num_data)\n",
    "split_idx['train'] = perm[:int(0.8*num_data)]\n",
    "split_idx['valid'] = perm[int(0.8*num_data): int(0.9*num_data)]\n",
    "split_idx['test'] = perm[int(0.9*num_data):]\n",
    "saver.save_split(split_idx, split_name = 'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b38b3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Copying mapping directory\n",
    "mapping_path = 'mapping/'\n",
    "\n",
    "# prepare mapping information first and store it under this directory (empty below).\n",
    "os.makedirs(mapping_path)\n",
    "os.mknod(os.path.join(mapping_path, 'README.md'))\n",
    "\n",
    "saver.copy_mapping_dir(mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4457f29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# 6. Saving task information\n",
    "saver.save_task_info(task_type = 'classification', eval_metric = 'rocauc', num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "19585e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Getting meta information dictionary\n",
    "meta_dict = saver.get_meta_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "334b9a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2995/2995 [00:00<00:00, 548724.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graphs...\n",
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'edge_index': array([[  0,   0,   1, ..., 137, 138, 138],\n",
      "       [  1,   2,   0, ..., 136,   1,   2]]), 'edge_feat': array([[1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [4],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [5],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [4],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [2],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [2],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]]), 'node_feat': array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ],\n",
      "       [ 0.63591 ,  0.28142 ,  1.103   , ...,  1.5154  ,  0.81081 ,\n",
      "         0.11142 ],\n",
      "       [ 1.0166  , -0.16772 ,  0.54235 , ...,  0.81724 ,  0.71405 ,\n",
      "        -0.081553],\n",
      "       ...,\n",
      "       [ 0.46748 , -0.73857 ,  0.23438 , ..., -0.089507, -0.2075  ,\n",
      "         0.49662 ],\n",
      "       [ 0.57288 ,  0.1999  ,  0.49409 , ...,  0.4532  , -0.35945 ,\n",
      "        -0.23636 ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
      "         0.      ]], dtype=float32), 'num_nodes': 139}, array([0., 0., 0., 0., 0., 0., 1.]))\n",
      "{'train': array([2819, 1758, 1963, ...,  197, 2505, 2543]), 'valid': array([ 499,  352, 1177, 2887, 1949,  109,  359,  350, 2092,  262, 2269,\n",
      "       1161, 2870, 1236,  542, 1692, 2896, 1214,  918,  135,  434, 1654,\n",
      "       2319,  234, 1863,  625, 1328,  670, 2976,   14,  744,   19, 1633,\n",
      "       1666,  820,  632, 1834, 1548, 1932,  151,  201, 1961,  435, 1634,\n",
      "       2777,   43,  170, 1151,  324, 2176,  532, 1326,  397,  973,  486,\n",
      "       2736, 2988, 1818, 2455, 1995,  591, 1296, 1218, 1409,  984,   82,\n",
      "        935, 2039,  996, 2410,  314,  898, 1064,  919, 1739, 2277,  819,\n",
      "         23, 2780, 2978,  143,  482, 1691, 2827, 1581,  410, 1444,  986,\n",
      "        737, 1587,  579, 2315, 2618, 2973, 1908, 2305, 2006, 2825,  572,\n",
      "       2952, 1629,   57, 1897,  697, 2015,  913, 2014,  231,  749, 1145,\n",
      "       2879,  754, 1459, 1630,  286, 2936, 1632,  303,  895,  313, 1414,\n",
      "        952,  518, 2125,  238,  212, 2500, 2342, 2317, 1316, 2174, 2229,\n",
      "        836, 2946, 1974, 1505, 1202,  379, 1406,  146,  517, 2311,   99,\n",
      "       1850, 2611, 1589, 2273,    3,  283, 1848, 2119, 2264, 2024, 1315,\n",
      "        750,  964,   76, 1073,  107,  229,  883, 2118,  689,  106, 1806,\n",
      "       1808, 1558,  611, 2246, 2294, 2244,  955,  442, 1393, 2103, 2314,\n",
      "        850, 2646,  970, 2320, 2405, 2890,   26, 2750, 2171, 1661, 2833,\n",
      "       2201, 2063, 2644, 1616, 1384,    0, 1004,  705,  373, 1930,  893,\n",
      "        103, 2803,  871,  938, 1382, 2571, 1377, 1254, 2371, 2943, 1799,\n",
      "       1297,  446, 2150, 2200, 2950, 2235, 2660, 2403, 1562,  385,  916,\n",
      "       2816, 1656,  559, 1191,  344, 2914, 1051, 2323, 2874, 1588, 2753,\n",
      "       2275,  377,   97,  593, 1861, 1047, 2559, 1698, 2708, 2705, 2402,\n",
      "        226, 1736, 2070,  888, 1343, 1944, 1083,  236, 2607, 1099, 2661,\n",
      "        680, 1211, 2356, 1876, 2335,  162,  742,  100, 2299, 1644, 1080,\n",
      "       1781, 2304, 1308, 2524,  280,  450, 1359, 2057,  880, 1684, 1948,\n",
      "       1983, 2821, 2869,  185, 1312, 2312,  729, 2184, 2038,  739, 1988,\n",
      "        513, 1570, 2562, 2584, 1574, 2840, 2882, 1760,  480, 2669, 2721,\n",
      "       2685, 1131]), 'test': array([ 923, 1046, 1366,  998, 1089, 1347,   78, 1192, 2756, 2519, 2522,\n",
      "       1869,  471, 1703, 1986, 1708,    6,  780,  161, 2871,  221, 1704,\n",
      "       2465, 2482, 1317,  685, 1376, 1792, 1464, 1987, 2574,  981, 1349,\n",
      "       2573,  848,  557, 1338,  250, 1770, 2857, 2897, 1413,  659, 2612,\n",
      "       2931, 2481, 2084, 1658, 2303,  158, 2860,  584,  400, 1494, 2716,\n",
      "        805, 2437, 1775, 2775, 1152,  461,  699, 1415, 1615, 2167, 2359,\n",
      "         36, 1061, 2238, 2873, 2181, 1188, 1502, 2697, 2003, 2765, 2786,\n",
      "       1856,  483, 2962, 1640, 1210, 1195,  908, 1852, 1524,  862, 1960,\n",
      "       1794,  620, 2214, 2013,  264, 1837,  753, 2165, 2053,  218, 1913,\n",
      "       1731, 1078,  730,  128, 1117,  907, 1265, 1053, 1220, 2885, 1129,\n",
      "        414,  395,  824, 1627, 2782, 1278, 2493,  792, 2250, 1766, 2096,\n",
      "       1006, 1522, 1219,   42, 2509,  539,   11, 2741, 1468,  169,   20,\n",
      "       1092,  696, 2353,  356,  870, 1346,   39, 1033, 2251, 2822, 1844,\n",
      "       2730,  485,  857,  734,  839, 1750, 1516, 2456, 2640,  776,  900,\n",
      "       2485, 2255, 2987,    4,  459,  803, 1396,  189,  187, 2049, 2285,\n",
      "       2430,  664, 1838, 2393, 2383,  972,  761, 1025,  294, 1342, 2120,\n",
      "       1017, 2347, 2564, 2052, 1546, 1067, 1153,  340,  698,  963, 2536,\n",
      "       2021,   47, 1535, 2480, 2243,  421,  926,  244, 1157, 1130, 2114,\n",
      "        832,  777, 1070, 1994, 1126, 1273, 1951,  865,  549, 1669,  603,\n",
      "        577,  184, 2124,  982,  733,  775, 1481,  444, 1021, 1488,  239,\n",
      "        132, 1900, 1810, 2033,  256,  384,  479, 2747, 2185, 1918,  833,\n",
      "        382,  289,  961, 2378,   68, 1171, 1052, 1185, 1689, 1098,  311,\n",
      "        904, 1790,  136,   80, 1649, 2525,  774,   56, 2139,  823, 1327,\n",
      "       1031,  181, 1591,  339, 2210,  873,  172, 2793, 1201, 2451, 1205,\n",
      "       1805, 1970,  628, 1638, 1260, 1605,  432,  600,  261, 2875, 1497,\n",
      "       2132, 1248, 1890, 1920, 2553,   37,  527,  306, 1917, 2071, 2042,\n",
      "       1206,  455,  726, 2432,  678, 1086, 2804, 1768, 2951, 2232,  933,\n",
      "       1855,  233,  343])}\n"
     ]
    }
   ],
   "source": [
    "# 8. Testing the dataset object\n",
    "from ogb.graphproppred import GraphPropPredDataset\n",
    "dataset = GraphPropPredDataset(dataset_name, meta_dict = meta_dict)\n",
    "\n",
    "# see if it is working properly\n",
    "print(dataset[0])\n",
    "print(dataset.get_idx_split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "166df835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 777)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['edge_index'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "90f496a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['edge_feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a3368f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139, 50)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['node_feat'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "227861af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.expand_dims(dataset[0][0]['edge_feat'], axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c37d45f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['edge_feat'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf532c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
